{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:11:22.850092Z",
     "start_time": "2025-06-16T13:11:22.846131Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "main_path = '/Users/farizrzayev/Desktop/projects/capslock/CapsLock Test task'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ccf3c107ed210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:11:27.585097Z",
     "start_time": "2025-06-16T13:11:27.578106Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d01c75120968a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:12:18.210023Z",
     "start_time": "2025-06-16T13:12:18.138413Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6594f35db8f4db9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:17:09.313836Z",
     "start_time": "2025-06-16T13:17:09.112205Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(main_path, 'CapsLock_internal_db_Test.csv'),  encoding='utf-16',  sep='\\t')\n",
    "df2 = pd.read_excel(os.path.join(main_path, 'CapsLock_Issued_Test.xlsx'))\n",
    "df3 = pd.read_excel(os.path.join(main_path, 'CapsLock_Leads_Test.xlsx'))\n",
    "df4 = pd.read_excel(os.path.join(main_path, 'CapsLock_Sets_Test.xlsx'))\n",
    "df5 = pd.read_excel(os.path.join(main_path, 'CapsLock_Tasks_Test.xlsx')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29bd47b131efe245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:19:22.147474Z",
     "start_time": "2025-06-16T13:19:22.143711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of internal db records 1170\n",
      "# of issues  records 128\n",
      "# of leads records 1054\n",
      "# of sets records 237\n",
      "# of tasks records 5592\n",
      "\n",
      "Null value counts:\n",
      "Internal DB nulls:\n",
      " Lavin Media Id     0\n",
      "Created time       0\n",
      "Source             0\n",
      "Landing page      16\n",
      "Thank You page    12\n",
      "dtype: int64\n",
      "\n",
      "Issues nulls:\n",
      " Net Sales              0\n",
      "Gross Sales            0\n",
      "Cancelled Sales        0\n",
      "Date                   0\n",
      "Created Date           0\n",
      "Created Time           0\n",
      "Status                 0\n",
      "Contact: Contact ID    0\n",
      "dtype: int64\n",
      "\n",
      "Leads nulls:\n",
      " Created Time                      20\n",
      "# Call Center Tasks Completed    177\n",
      "Lavin Media ID                    29\n",
      "Contact ID                       756\n",
      "Region                             0\n",
      "dtype: int64\n",
      "\n",
      "Sets nulls:\n",
      " Date                   0\n",
      "Created Date           0\n",
      "Created Time           0\n",
      "Status                 0\n",
      "Contact: Contact ID    0\n",
      "dtype: int64\n",
      "\n",
      "Tasks nulls:\n",
      " Created Time                      327\n",
      "Call Result                       375\n",
      "Lavin Media ID                    153\n",
      "Converted Contact: Contact ID    5301\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "result = {\n",
    "    \"df -> internal db\": df.columns,\n",
    "    \"df2 -> issues \":df2.columns,\n",
    "    \"df3 -> Leads\":df3.columns,\n",
    "    \"df4 -> Sets\":df4.columns,\n",
    "    \"df5 -> Tasks\":df5.columns\n",
    "}\n",
    "result\n",
    "\n",
    "print(\"# of internal db records\", len(df))\n",
    "print(\"# of issues  records\", len(df2))\n",
    "print(\"# of leads records\", len(df3))\n",
    "print(\"# of sets records\", len(df4))\n",
    "print(\"# of tasks records\", len(df5))\n",
    "\n",
    "# Check for null values in each DataFrame\n",
    "\n",
    "print(\"\\nNull value counts:\")\n",
    "print(\"Internal DB nulls:\\n\", df.isnull().sum())\n",
    "print(\"\\nIssues nulls:\\n\", df2.isnull().sum())\n",
    "print(\"\\nLeads nulls:\\n\", df3.isnull().sum())\n",
    "print(\"\\nSets nulls:\\n\", df4.isnull().sum())\n",
    "print(\"\\nTasks nulls:\\n\", df5.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5fd0e01-d70d-48a0-8209-dfd6179039aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created Time</th>\n",
       "      <th># Call Center Tasks Completed</th>\n",
       "      <th>Lavin Media ID</th>\n",
       "      <th>Contact ID</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-22 12:07:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-22 12:19:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-22 12:25:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-22 13:21:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-22 14:56:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>2020-12-30 10:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5042.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wilmington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>2020-12-23 18:58:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wilmington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>2020-12-29 13:20:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4322.0</td>\n",
       "      <td>0031G000018rYx5</td>\n",
       "      <td>Wilmington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>2019-11-30 06:01:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wilmington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>2020-12-30 09:27:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4948.0</td>\n",
       "      <td>0031G000018rlva</td>\n",
       "      <td>Wilmington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Created Time  # Call Center Tasks Completed  Lavin Media ID  \\\n",
       "0    2020-12-22 12:07:00                            3.0          1550.0   \n",
       "1    2020-12-22 12:19:00                            1.0          1559.0   \n",
       "2    2020-12-22 12:25:00                            6.0          1563.0   \n",
       "3    2020-12-22 13:21:00                           11.0          1607.0   \n",
       "4    2020-12-22 14:56:00                           11.0          1650.0   \n",
       "...                  ...                            ...             ...   \n",
       "1049 2020-12-30 10:10:00                            NaN          5042.0   \n",
       "1050 2020-12-23 18:58:00                            8.0          2394.0   \n",
       "1051 2020-12-29 13:20:00                            2.0          4322.0   \n",
       "1052 2019-11-30 06:01:00                           13.0          4440.0   \n",
       "1053 2020-12-30 09:27:00                            0.0          4948.0   \n",
       "\n",
       "           Contact ID      Region  \n",
       "0                 NaN     Atlanta  \n",
       "1                 NaN     Atlanta  \n",
       "2                 NaN     Atlanta  \n",
       "3                 NaN     Atlanta  \n",
       "4                 NaN     Atlanta  \n",
       "...               ...         ...  \n",
       "1049              NaN  Wilmington  \n",
       "1050              NaN  Wilmington  \n",
       "1051  0031G000018rYx5  Wilmington  \n",
       "1052              NaN  Wilmington  \n",
       "1053  0031G000018rlva  Wilmington  \n",
       "\n",
       "[1054 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b79c9e9178c9f21c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:35:18.601714Z",
     "start_time": "2025-06-16T13:35:18.599059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df -> internal db': Index(['Lavin Media Id', 'Created time', 'Source', 'Landing page',\n",
       "        'Thank You page'],\n",
       "       dtype='object'),\n",
       " 'df2 -> issues ': Index(['Net Sales', 'Gross Sales', 'Cancelled Sales', 'Date', 'Created Date',\n",
       "        'Created Time', 'Status', 'Contact: Contact ID'],\n",
       "       dtype='object'),\n",
       " 'df3 -> Leads': Index(['Created Time', '# Call Center Tasks Completed', 'Lavin Media ID',\n",
       "        'Contact ID', 'Region'],\n",
       "       dtype='object'),\n",
       " 'df4 -> Sets': Index(['Date', 'Created Date', 'Created Time', 'Status',\n",
       "        'Contact: Contact ID'],\n",
       "       dtype='object'),\n",
       " 'df5 -> Tasks': Index(['Created Time', 'Call Result', 'Lavin Media ID',\n",
       "        'Converted Contact: Contact ID'],\n",
       "       dtype='object')}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.loc[df['Landing page'].isnull(),:]\n",
    "\n",
    "# # len(df3), len(df)\n",
    "\n",
    "# merged_df = pd.merge(df3, df, how = \"left\", left_on='Lavin Media ID', right_on='Lavin Media Id')\n",
    "# merged_df.isnull().sum()\n",
    "\n",
    "# len(df3.loc[~df3['Lavin Media ID'].isnull()])\n",
    "\n",
    "result = {\n",
    "    \"df -> internal db\": df.columns,\n",
    "    \"df2 -> issues \":df2.columns,\n",
    "    \"df3 -> Leads\":df3.columns,\n",
    "    \"df4 -> Sets\":df4.columns,\n",
    "    \"df5 -> Tasks\":df5.columns\n",
    "}\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb7c0d87c34a3889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:23:22.045301Z",
     "start_time": "2025-06-16T13:23:22.042410Z"
    }
   },
   "outputs": [],
   "source": [
    "issues = df2.copy()\n",
    "leads = df3.copy()\n",
    "sets = df4.copy()\n",
    "tasks = df5.copy()\n",
    "internal_db = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "267c1f4b-ce20-40e6-b122-97333fa91fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Standardize Contact ID column names across datasets\n",
    "# Rename columns to consistent 'Contact_ID'\n",
    "issues = issues.rename(columns={'Contact: Contact ID': 'Contact_ID'})\n",
    "sets = sets.rename(columns={'Contact: Contact ID': 'Contact_ID'})\n",
    "leads = leads.rename(columns={'Contact ID': 'Contact_ID'})\n",
    "tasks = tasks.rename(columns={'Converted Contact: Contact ID': 'Contact_ID'})\n",
    "internal_db = internal_db.rename(columns={'Lavin Media Id': 'Lavin_Media_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4b0678f6cb8b472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:31:49.242805Z",
     "start_time": "2025-06-16T13:31:49.218630Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Contact_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zk/pmff98r10hb3xqn6wgxtg94h0000gn/T/ipykernel_3048/213958276.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m## Assuming you've already loaded your dataframes as:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# internal_db, issues, leads, sets, tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/capslock/.venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10835\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10836\u001b[0m     ) -> DataFrame:\n\u001b[1;32m  10837\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10839\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10840\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10841\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10842\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/capslock/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/capslock/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/capslock/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/capslock/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Contact_ID'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Assuming you've already loaded your dataframes as:\n",
    "# internal_db, issues, leads, sets, tasks\n",
    "\n",
    "## Step 2: Create contact-level base dataset from internal_db\n",
    "# Start with internal_db as our base\n",
    "master_df = internal_db.copy()\n",
    "\n",
    "## Step 3: Join Issues (1:1 relationship)\n",
    "master_df = master_df.merge(\n",
    "    issues,\n",
    "    on='Contact_ID',\n",
    "    how='left',\n",
    "    suffixes=('', '_issues')\n",
    ")\n",
    "\n",
    "## Step 4: Join Sets (1:1 relationship)\n",
    "master_df = master_df.merge(\n",
    "    sets,\n",
    "    on='Contact_ID',\n",
    "    how='left',\n",
    "    suffixes=('', '_sets')\n",
    ")\n",
    "\n",
    "## Step 5: Join Leads (1:1 relationship)\n",
    "master_df = master_df.merge(\n",
    "    leads,\n",
    "    on='Contact_ID',\n",
    "    how='left',\n",
    "    suffixes=('', '_leads')\n",
    ")\n",
    "\n",
    "## Step 6: Handle Tasks (1:many relationship) - create aggregated metrics\n",
    "# First calculate task aggregates\n",
    "task_agg = tasks.groupby('Contact_ID').agg({\n",
    "    'Created Time': ['count', 'max'],  # Count of tasks, most recent task\n",
    "    'Call Result': lambda x: x.mode()[0] if len(x.mode()) > 0 else None  # Most common call result\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-index columns\n",
    "task_agg.columns = ['Contact_ID', 'Task_Count', 'Last_Task_Date', 'Most_Common_Call_Result']\n",
    "\n",
    "# Then merge with master\n",
    "master_df = master_df.merge(\n",
    "    task_agg,\n",
    "    on='Contact_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "## Step 7: Clean up merged columns\n",
    "# Drop duplicate columns from merges\n",
    "for col in master_df.columns:\n",
    "    if col.endswith('_issues') or col.endswith('_sets') or col.endswith('_leads'):\n",
    "        original_col = col.split('_')[0]\n",
    "        if original_col in master_df.columns:\n",
    "            master_df = master_df.drop(columns=[col])\n",
    "\n",
    "## Step 8: Handle nulls appropriately for key metrics\n",
    "# For numerical fields like 'Call Center Tasks Completed', fill nulls with 0\n",
    "if '# Call Center Tasks Completed' in master_df.columns:\n",
    "    master_df['# Call Center Tasks Completed'] = master_df['# Call Center Tasks Completed'].fillna(0)\n",
    "\n",
    "# For categorical fields, you might want to keep nulls or fill with 'Unknown'\n",
    "categorical_cols = ['Status', 'Call Result', 'Region']\n",
    "for col in categorical_cols:\n",
    "    if col in master_df.columns:\n",
    "        master_df[col] = master_df[col].fillna('Unknown')\n",
    "\n",
    "## Step 9: Add source tracking (optional)\n",
    "master_df['Data_Source'] = 'Integrated'\n",
    "\n",
    "## Final output\n",
    "print(f\"Final integrated dataset shape: {master_df.shape}\")\n",
    "print(\"\\nNull value counts in integrated dataset:\")\n",
    "print(master_df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7791271dc4e298",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:36:07.864011Z",
     "start_time": "2025-06-16T13:36:07.854447Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d2c12d3ef9100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:36:52.316693Z",
     "start_time": "2025-06-16T13:36:52.311694Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
